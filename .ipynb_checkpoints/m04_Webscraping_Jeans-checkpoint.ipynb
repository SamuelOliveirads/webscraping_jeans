{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eaa1ac2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Questão de Negócio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd05c7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A empresa Star Jeans! Eduardo e Marcelo são dois brasileiros, amigos e sócios de empreendimento. \n",
    "\n",
    "Depois de vários negócio bem sucedidos, eles estão planejando entrar no mercado de moda\n",
    "dos USA como um modelo de negócio do tipo E-commerce.\n",
    "\n",
    "A idéia inicial é entrar no mercado com apenas um produto e para um público específico, no caso\n",
    "o produto seria calças Jenas para o público masculino. O objetivo é manter o custo de operação\n",
    "baixo e escalar a medida que forem conseguindo clientes.\n",
    "\n",
    "Porém, mesmo com o produto de entrada e a audiência definidos, os dois sócios não tem experiência\n",
    "nesse mercado de moda e portanto não sabem definir coisas básicas como preço, o tipo de calça e\n",
    "o material para a fabricação de cada peça.\n",
    "\n",
    "Assim, os dois sócios contrataram uma consultoria de Ciência de Dados para responder as seguintes\n",
    "perguntas: \n",
    "1. Qual o melhor preço de venda para as calças? \n",
    "2. Quantos tipos de calças e suas cores para o produto inicial? \n",
    "3. Quais as matérias-prima necessárias para confeccionar as calças?\n",
    "\n",
    "As principais concorrentes da empresa Start Jeans são as americadas H&M e Macys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a60f16",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 0.0 Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0774dc6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T14:37:43.175812Z",
     "start_time": "2022-08-05T14:37:40.912023Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "import inflection\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ac345",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 0.1 Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b2bba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T14:37:43.190806Z",
     "start_time": "2022-08-05T14:37:43.177853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    plt.style.use('bmh')\n",
    "    plt.rcParams['figure.figsize'] = [25,12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "    \n",
    "    display( HTML( '<style>.container{width:100% !important; }</style>'))\n",
    "    pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "    \n",
    "    # ignora future warnings\n",
    "    #warnings.filterwarnings('ignore')\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479a6ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T14:37:43.458104Z",
     "start_time": "2022-08-05T14:37:43.440127Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53bdf7",
   "metadata": {},
   "source": [
    "# Organização do ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614dd80",
   "metadata": {},
   "source": [
    "# 1.0 Extração de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a32d5a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T14:45:10.215207Z",
     "start_time": "2022-08-05T14:45:07.816196Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------ Make URL with all products -----------------------------\n",
    "# URL\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "\n",
    "# parameters\n",
    "headers = {'User-Agent': 'Mozilla/5.0 {Macintosh; Intel Mac Os X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36}'}\n",
    "\n",
    "# make request\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "# Instance Beautiful Soup\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "# collect all products available\n",
    "total_item = soup.find_all('h2', class_='load-more-heading')[0].get('data-total')\n",
    "\n",
    "# detect total page numbers\n",
    "page_number = np.ceil(int(total_item)/36)\n",
    "\n",
    "# create link from total of page numbers\n",
    "url = url + '?page-size=' + str(int(page_number*36))\n",
    "\n",
    "\n",
    "#------------------ New Request with all products ----------------\n",
    "# make request\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "# Instance Beautiful Soup\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "# ---------------- Product Data ---------------------------------\n",
    "\n",
    "# extract all products\n",
    "products = soup.find('ul', class_='products-listing small')\n",
    "\n",
    "product_list = products.find_all('article', class_='hm-product-item')\n",
    "\n",
    "# product id\n",
    "product_id = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "# product_category\n",
    "product_category = [p.get('data-category') for p in product_list]\n",
    "\n",
    "# product name\n",
    "product_list = products.find_all('a', class_='link')\n",
    "product_name = [p.get_text() for p in product_list]\n",
    "\n",
    "# price\n",
    "product_list = products.find_all('span', class_='price regular')\n",
    "product_price = [p.get_text() for p in product_list]\n",
    "\n",
    "# merge scrapy into data frame\n",
    "data = pd.DataFrame([product_id, product_category, product_name, product_price]).T\n",
    "data.columns = ['product_id', 'product_category', 'product_name', 'product_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a986f6",
   "metadata": {},
   "source": [
    "# 2.0 Extração de dados por produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6f44557b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T17:14:19.177639Z",
     "start_time": "2022-08-05T17:13:08.031934Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product: https://www2.hm.com/en_us/productpage.0971061002.html\n",
      "color: https://www2.hm.com/en_us/productpage.0971061001.html\n",
      "color: https://www2.hm.com/en_us/productpage.0971061002.html\n",
      "color: https://www2.hm.com/en_us/productpage.0971061004.html\n",
      "color: https://www2.hm.com/en_us/productpage.0971061005.html\n",
      "color: https://www2.hm.com/en_us/productpage.0971061006.html\n",
      "product: https://www2.hm.com/en_us/productpage.0985159007.html\n",
      "color: https://www2.hm.com/en_us/productpage.0985159001.html\n",
      "color: https://www2.hm.com/en_us/productpage.0985159002.html\n",
      "product: https://www2.hm.com/en_us/productpage.0985159001.html\n",
      "color: https://www2.hm.com/en_us/productpage.0985159001.html\n",
      "color: https://www2.hm.com/en_us/productpage.0985159002.html\n",
      "color: https://www2.hm.com/en_us/productpage.0985159003.html\n",
      "color: https://www2.hm.com/en_us/productpage.0985159004.html\n",
      "color: https://www2.hm.com/en_us/productpage.0985159005.html\n",
      "product: https://www2.hm.com/en_us/productpage.1024256001.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256001.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256002.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256003.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256004.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256005.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256006.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256007.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256008.html\n",
      "product: https://www2.hm.com/en_us/productpage.1008549001.html\n",
      "color: https://www2.hm.com/en_us/productpage.1008549001.html\n",
      "color: https://www2.hm.com/en_us/productpage.1008549002.html\n",
      "color: https://www2.hm.com/en_us/productpage.1008549003.html\n",
      "color: https://www2.hm.com/en_us/productpage.1008549004.html\n",
      "color: https://www2.hm.com/en_us/productpage.1008549006.html\n",
      "color: https://www2.hm.com/en_us/productpage.1008549007.html\n",
      "color: https://www2.hm.com/en_us/productpage.1008549008.html\n",
      "product: https://www2.hm.com/en_us/productpage.0979945003.html\n",
      "color: https://www2.hm.com/en_us/productpage.0979945001.html\n",
      "color: https://www2.hm.com/en_us/productpage.0979945002.html\n",
      "color: https://www2.hm.com/en_us/productpage.0979945003.html\n",
      "color: https://www2.hm.com/en_us/productpage.0979945009.html\n",
      "product: https://www2.hm.com/en_us/productpage.1024256002.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256001.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256002.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256003.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256004.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256005.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256006.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256007.html\n",
      "color: https://www2.hm.com/en_us/productpage.1024256008.html\n",
      "product: https://www2.hm.com/en_us/productpage.0979945001.html\n",
      "color: https://www2.hm.com/en_us/productpage.0979945001.html\n",
      "color: https://www2.hm.com/en_us/productpage.0979945002.html\n",
      "color: https://www2.hm.com/en_us/productpage.0979945003.html\n",
      "color: https://www2.hm.com/en_us/productpage.0979945009.html\n",
      "product: https://www2.hm.com/en_us/productpage.1008549006.html\n",
      "color: https://www2.hm.com/en_us/productpage.1008549001.html\n",
      "product: https://www2.hm.com/en_us/productpage.0690449022.html\n",
      "color: https://www2.hm.com/en_us/productpage.0690449001.html\n",
      "product: https://www2.hm.com/en_us/productpage.0979945002.html\n",
      "color: https://www2.hm.com/en_us/productpage.0979945001.html\n",
      "product: https://www2.hm.com/en_us/productpage.1013317006.html\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#url = 'https://www2.hm.com/en_us/productpage.0690449022.html' # test for one product\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m page \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Beautiful Soup\u001b[39;00m\n\u001b[0;32m     21\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Empty dataframe\n",
    "df_compositions = pd.DataFrame()\n",
    "\n",
    "# unique columns for all products\n",
    "aux = []\n",
    "\n",
    "cols = {'Art. No.', 'Care instructions', 'Composition', 'Concept', 'Description', 'Fit', 'Imported',\n",
    " 'Material', 'More sustainable materials', 'Nice to know', 'Size', 'color_id', \n",
    " 'messages.clothingStyle', 'messages.garmentLength', 'messages.waistRise', 'style_id'}\n",
    "df_pattern = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    #Api Request\n",
    "    url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id'] + '.html'\n",
    "    print(f'product: {url}')\n",
    "    #url = 'https://www2.hm.com/en_us/productpage.0690449022.html' # test for one product\n",
    "\n",
    "    page = requests.get(url, headers=headers)\n",
    "\n",
    "    # Beautiful Soup\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        # color name\n",
    "        product_list = soup.find_all('a', {'class':['filter-option miniature', 'filter-option miniature active']} )\n",
    "        color_name = [p.get('data-color') for p in product_list]\n",
    "\n",
    "        # product id\n",
    "        product_id = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "        df_color = pd.DataFrame( [product_id, color_name]).T\n",
    "        df_color.columns = ['product_id', 'color_name']\n",
    "\n",
    "        #-------------------------- request detail products for colors -----------------------------\n",
    "        for j in range(len(df_color)):\n",
    "            #Api Request\n",
    "            url = 'https://www2.hm.com/en_us/productpage.' + df_color.loc[j, 'product_id'] + '.html'\n",
    "            print(f'color: {url}')\n",
    "\n",
    "            page = requests.get(url, headers=headers)\n",
    "\n",
    "            # Beautiful Soup\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "            size = soup.find_all('ul', class_='picker-list scrollable-list')\n",
    "        \n",
    "            # product name\n",
    "            products = soup.find_all('section', class_='product-name-price')\n",
    "            product_name = products[0].find('h1').get_text()\n",
    "\n",
    "            # price\n",
    "            product_price = products[0].find('span').get_text()\n",
    "            product_price = re.findall(r'\\d+\\.?\\d', product_price)[0]\n",
    "\n",
    "            #------------------------composition----------------------------\n",
    "\n",
    "            product_composition_list = soup.find_all('div', class_='details-attributes-list-item')\n",
    "            product_composition = [list(filter(None, p.get_text().split('\\n'))) for p in product_composition_list]\n",
    "\n",
    "            # rename dataframe\n",
    "            df_composition = pd.DataFrame(product_composition).T\n",
    "            df_composition.columns = df_composition.iloc[0]\n",
    "\n",
    "            # delete first row\n",
    "            df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "\n",
    "            # Remove shell, pocket and lining\n",
    "            df_composition['Composition'] = df_composition['Composition'].replace('Shell: ', '', regex=True)\n",
    "            df_composition['Composition'] = df_composition['Composition'].replace('Pocket lining: ', '', regex=True)\n",
    "            df_composition['Composition'] = df_composition['Composition'].replace('Pocket: ', '', regex=True)\n",
    "            df_composition['Composition'] = df_composition['Composition'].replace('Lining: ', '', regex=True)\n",
    "\n",
    "            # garantee the same number of columns\n",
    "            df_composition = pd.concat([df_pattern, df_composition], axis=0)\n",
    "\n",
    "            # keep new columns if they shows  up\n",
    "            aux = aux + df_composition.columns.tolist()\n",
    "\n",
    "            # collect most important columns\n",
    "            df_composition = df_composition[['Art. No.', 'Composition', 'Size', 'Fit', \n",
    "                                             'Material', 'Description']]\n",
    "\n",
    "            # rename columns\n",
    "            df_composition.columns = ['product_id', 'composition', 'size', 'fit', 'material', 'description']\n",
    "\n",
    "            # adding name and price\n",
    "            df_composition['product_name'] = product_name\n",
    "            df_composition['product_price'] = product_price\n",
    "\n",
    "            # merge data color + decomposition\n",
    "            df_composition = pd.merge(df_composition, df_color, how='left', on='product_id')\n",
    "\n",
    "            # all products\n",
    "            df_compositions = pd.concat([df_compositions, df_composition], axis=0)\n",
    "    except:\n",
    "        continue\n",
    "# Join showroom data + details\n",
    "df_compositions['style_id'] = df_compositions['product_id'].apply(lambda x: x[:-3])\n",
    "df_compositions['color_id'] = df_compositions['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "\n",
    "# scrapy datetime\n",
    "df_compositions['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# saving scraping\n",
    "# df_compositions.to_csv('F:/SamuelOliveiraAlvesd/Desktop/Data_Science/Projetos/Ds_ao_Dev/webscraping_jeans/dataset/scraping_hm_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d3e9e5",
   "metadata": {},
   "source": [
    "# 3.0 Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c6ea7de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T14:52:50.080955Z",
     "start_time": "2022-08-05T14:52:49.904056Z"
    }
   },
   "outputs": [],
   "source": [
    "# make new copy\n",
    "#data1 = df_compositions.copy()\n",
    "\n",
    "# collect all collumns\n",
    "old_cols = ['product_id', 'composition', 'size', 'fit', 'material', 'description',\n",
    "       'product_name', 'product_price', 'color_name', 'style_id', 'color_id',\n",
    "       'scrapy_datetime']\n",
    "\n",
    "# function for new format for each collumn\n",
    "snakecase = lambda x : inflection.underscore(x)\n",
    "\n",
    "# applying change in columns for snakecase and underline\n",
    "new_cols = list(map(snakecase, old_cols))\n",
    "\n",
    "data1.columns = new_cols\n",
    "\n",
    "# Create Collumn Inner Leg\n",
    "data1['inner_leg_size'] = data1['size'].apply(lambda x: 89.5 if x=='Inner leg: Length: 89.5 cm (Size 33)'\n",
    "                                              else 0)\n",
    "\n",
    "# Create collumn Waist\n",
    "data1['waist_size'] = data1['size'].apply(lambda x: 90.5 if x=='Waist: Circumference: 90.5 cm (Size 33)'\n",
    "                                              else 0)\n",
    "\n",
    "# fillout size value\n",
    "data1['size'] = data1['size'].apply(lambda x: 0 if pd.isnull(x) else 33)\n",
    "\n",
    "# drop duplicates\n",
    "#data1 = data1.drop_duplicates()\n",
    "\n",
    "# product_name - undercase and removing special characters\n",
    "data1['product_name'] = data1['product_name'].apply(lambda x: x.replace(' ', '_').replace('®', '').lower())\n",
    "\n",
    "# color_name - undercase and removing space\n",
    "data1['color_name'] = data1['color_name'].apply(lambda x: x.replace(' ', '_').replace('/', '_').lower())\n",
    "\n",
    "# fit - undercase and removing space\n",
    "data1['fit'] = data1['fit'].apply(lambda x: x.replace(' ', '_').lower())\n",
    "\n",
    "#--------------Cleaning composition------------------------------------------------\n",
    "\n",
    "# break composition by comma\n",
    "dfaux = data1['composition'].str.split(',', expand=True).reset_index(drop=True)\n",
    "\n",
    "# choose order from columns\n",
    "df_ref = pd.DataFrame(index=np.arange(len(data1)), columns=['cotton', 'polyester', 'elastomultiester', 'spandex'])\n",
    "\n",
    "#--------------------------  cotton ----------------------------------------------\n",
    "# Collect cotton from first collumn\n",
    "df_cotton = dfaux.loc[dfaux[0].str.contains('Cotton', na=True), 0]\n",
    "df_cotton.name = 'cotton'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_cotton], axis=1)\n",
    "\n",
    "# Collect cotton from second collumn\n",
    "df_cotton2 = dfaux.loc[dfaux[1].str.contains('Cotton', na=True), 1]\n",
    "df_cotton2.name = 'cotton2'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_cotton2], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# merge results from cotton in one collumn\n",
    "df_ref['cotton'] = df_ref.apply(lambda x: x['cotton'] if pd.isna(x['cotton2']) else x['cotton2'], axis=1)\n",
    "df_ref.drop(columns='cotton2', inplace=True)\n",
    "\n",
    "#-------------------------- polyester ----------------------------------------------\n",
    "# Collect polyester from first collumn\n",
    "df_polyester = dfaux.loc[dfaux[0].str.contains('Polyester', na=True), 0]\n",
    "df_polyester.name = 'polyester'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_polyester], axis=1)\n",
    "\n",
    "# Collect polyester from second collumn\n",
    "df_polyester2 = dfaux.loc[dfaux[1].str.contains('Polyester', na=True), 1]\n",
    "df_polyester2.name = 'polyester2'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_polyester2], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# merge results from cotton in one collumn\n",
    "df_ref['polyester'] = df_ref.apply(lambda x: x['polyester'] if pd.isna(x['polyester2']) else x['polyester2'], axis=1)\n",
    "df_ref.drop(columns='polyester2', inplace=True)\n",
    "\n",
    "#-------------------------- Elastomultiester ----------------------------------------------\n",
    "# Collect elastomultiester from second collumn\n",
    "df_elastomultiester = dfaux.loc[dfaux[1].str.contains('Elastomultiester', na=True), 1]\n",
    "df_elastomultiester.name = 'elastomultiester'\n",
    "\n",
    "# merge results\n",
    "df_ref = pd.concat([df_ref, df_elastomultiester], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "#-------------------------- spandex ----------------------------------------------\n",
    "# Collect spandex from second collumn\n",
    "df_spandex = dfaux.loc[dfaux[1].str.contains('Spandex', na=True), 1]\n",
    "df_spandex.name = 'spandex'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_spandex], axis=1)\n",
    "\n",
    "# Collect spandex from third collumn\n",
    "df_spandex2 = dfaux.loc[dfaux[2].str.contains('Spandex', na=True), 2]\n",
    "df_spandex2.name = 'spandex2'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_spandex2], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# merge results from cotton in one collumn\n",
    "df_ref['spandex'] = df_ref.apply(lambda x: x['spandex'] if pd.isna(x['spandex2']) else x['spandex2'], axis=1)\n",
    "df_ref.drop(columns='spandex2', inplace=True)\n",
    "\n",
    "# format composition data\n",
    "df_ref['cotton'] = df_ref['cotton'].apply(lambda x: int(re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "df_ref['polyester'] = df_ref['polyester'].apply(lambda x: int(re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "df_ref['elastomultiester'] = df_ref['elastomultiester'].apply(lambda x: int(re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "df_ref['spandex'] = df_ref['spandex'].apply(lambda x: int(re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "\n",
    "# drop all rows with NA in all collumns\n",
    "df_ref.dropna(axis=0, how='all', inplace=True)\n",
    "df_ref.fillna(0, inplace=True)\n",
    "\n",
    "# reset index and final join\n",
    "data1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data1 = pd.concat([data1, df_ref], axis=1)\n",
    "\n",
    "# description - undercase and removing space\n",
    "data1['description'] = data1['description'].apply(lambda x: x.replace(' ', '_').lower())\n",
    "\n",
    "# material - undercase and removing space\n",
    "data1['material'] = data1['material'].apply(lambda x: x.replace(' ', '_').lower())\n",
    "\n",
    "# product_price\n",
    "data1['product_price'] = data1['product_price'].astype('float64')\n",
    "\n",
    "# cotton\n",
    "data1['cotton'] = data1['cotton'].astype('float64')\n",
    "\n",
    "# polyester\n",
    "data1['polyester'] = data1['polyester'].astype('float64')\n",
    "\n",
    "# elastomultiester\n",
    "data1['elastomultiester'] = data1['elastomultiester'].astype('float64')\n",
    "\n",
    "# spandex\n",
    "data1['spandex'] = data1['spandex'].astype('float64')\n",
    "\n",
    "# drop composition\n",
    "data1.drop(columns='composition', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e8378",
   "metadata": {},
   "source": [
    "# 4.0 Insert into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e19ff0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-03T19:48:42.598441Z",
     "start_time": "2022-08-03T19:48:42.585448Z"
    }
   },
   "outputs": [],
   "source": [
    "# organize columns\n",
    "data1 = data1[['product_id', 'style_id', 'color_id', 'product_name', 'color_name','fit', 'size', 'inner_leg_size', 'waist_size',\n",
    "               'cotton', 'polyester', 'elastomultiester', 'spandex', 'material', 'description', 'scrapy_datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0102502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T18:17:00.387519Z",
     "start_time": "2022-08-05T18:17:00.368390Z"
    }
   },
   "outputs": [],
   "source": [
    "# create query from name of columns in database\n",
    "query_showroom_schema = \"\"\"\n",
    "    CREATE TABLE showroom(\n",
    "        product_id           TEXT,\n",
    "        style_id             TEXT,\n",
    "        color_id             TEXT,\n",
    "        product_name         TEXT,\n",
    "        color_name           TEXT,\n",
    "        fit                  TEXT,\n",
    "        size                 INTEGER,\n",
    "        inner_leg_size       REAL,\n",
    "        waist_size           REAL,\n",
    "        cotton               REAL,\n",
    "        polyester            REAL,\n",
    "        elastomultiester     REAL,\n",
    "        spandex              REAL,\n",
    "        material             TEXT,\n",
    "        description          TEXT,\n",
    "        scrapy_datetime      TEXT\n",
    "        )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ec869edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T18:17:02.172741Z",
     "start_time": "2022-08-05T18:17:02.152382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Connect and create an database\n",
    "conn = sqlite3.connect('hm_db.sqlite')\n",
    "\n",
    "# run query\n",
    "cursor = conn.execute(query_showroom_schema)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89357c77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-03T19:50:25.303987Z",
     "start_time": "2022-08-03T19:50:25.215999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1708"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect in the database already create\n",
    "conn = create_engine('sqlite:///hm_db.sqlite', echo=False)\n",
    "\n",
    "# insert data to table\n",
    "data1.to_sql('showroom', con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9e4be4",
   "metadata": {},
   "source": [
    "# Fazer um segundo scraping com a tabela size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e2f9a",
   "metadata": {},
   "source": [
    "- Dropar a coleta do size e suas features\n",
    "\n",
    "- Olhar porque o elastomultiester não tem nada = Nesse jupyter está coletando normal\n",
    "\n",
    "- Loop pela página = inserido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3e38feb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T18:17:13.864099Z",
     "start_time": "2022-08-05T18:17:13.857101Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM showroom\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "91759792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T18:17:14.750882Z",
     "start_time": "2022-08-05T18:17:14.743885Z"
    }
   },
   "outputs": [],
   "source": [
    "conn = create_engine('sqlite:///hm_db.sqlite', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0144dedb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T18:17:16.265448Z",
     "start_time": "2022-08-05T18:17:16.256453Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "96d57a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T18:16:12.702890Z",
     "start_time": "2022-08-05T18:16:12.696883Z"
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "DELETE FROM showroom\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d9f2c385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T18:16:39.244791Z",
     "start_time": "2022-08-05T18:16:39.080895Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such table: showroom\n[SQL: \nSELECT * FROM showroom]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1821\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: showroom",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [97]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\pandas\\io\\sql.py:399\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03mparameter will be converted to UTC.\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    398\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m--> 399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\pandas\\io\\sql.py:1557\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;124;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1553\u001b[0m \n\u001b[0;32m   1554\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 1557\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1558\u001b[0m columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\pandas\\io\\sql.py:1402\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;124;03m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectable\u001b[38;5;241m.\u001b[39mexecution_options()\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\util\\deprecations.py:402\u001b[0m, in \u001b[0;36m_decorate_with_warning.<locals>.warned\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_warning:\n\u001b[0;32m    401\u001b[0m     _warn_with_version(message, version, wtype, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3176\u001b[0m, in \u001b[0;36mEngine.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   3158\u001b[0m \u001b[38;5;124;03m\"\"\"Executes the given construct and returns a\u001b[39;00m\n\u001b[0;32m   3159\u001b[0m \u001b[38;5;124;03m:class:`_engine.CursorResult`.\u001b[39;00m\n\u001b[0;32m   3160\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3173\u001b[0m \n\u001b[0;32m   3174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3175\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect(close_with_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 3176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mexecute(statement, \u001b[38;5;241m*\u001b[39mmultiparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1291\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(statement, util\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[0;32m   1283\u001b[0m     util\u001b[38;5;241m.\u001b[39mwarn_deprecated_20(\n\u001b[0;32m   1284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a string to Connection.execute() is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in version 2.0.  Use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver-level SQL string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1289\u001b[0m     )\n\u001b[1;32m-> 1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_EMPTY_EXECUTION_OPTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1300\u001b[0m     meth \u001b[38;5;241m=\u001b[39m statement\u001b[38;5;241m.\u001b[39m_execute_on_connection\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1595\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[1;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[0;32m   1585\u001b[0m         (\n\u001b[0;32m   1586\u001b[0m             statement,\n\u001b[0;32m   1587\u001b[0m             distilled_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1591\u001b[0m             statement, distilled_parameters, execution_options\n\u001b[0;32m   1592\u001b[0m         )\n\u001b[0;32m   1594\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[1;32m-> 1595\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1603\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future:\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1859\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1862\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2043\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2041\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(newraise, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m   2042\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m-> 2043\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2044\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqlalchemy_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\n\u001b[0;32m   2045\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2046\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2047\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(exc_info[\u001b[38;5;241m1\u001b[39m], with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1817\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1821\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1826\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1830\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1831\u001b[0m     )\n",
      "File \u001b[1;32mF:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\Scrapping_Jeans\\lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: showroom\n[SQL: \nSELECT * FROM showroom]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "pd.read_sql_query(query, con=conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
